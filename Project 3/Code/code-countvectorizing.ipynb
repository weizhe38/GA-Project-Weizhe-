{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07be20e0",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 3: Web APIs & NLP - Count Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd4626",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4968a9",
   "metadata": {},
   "source": [
    "Current classifying model using straightforward keywords such as ‘bootcamp’ and ‘coding’ yields around 79% accuracy.\n",
    "\n",
    "Build a model with >90% accuracy that helps to identify between those who are looking for bootcamp style learning vs computer science majors/prospective students based on the words they use online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230168f",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Purpose:\n",
    "#### Notebook contains codes for:\n",
    "- Count Vectorizing data preprocessing method.\n",
    "- Gridsearch CV (model optimization) on selected Models such as Bernoulli NB, Multinomial NB, KNN, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fea2e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85de31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import jupyternotify\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#change display options\n",
    "pd.set_option(\"display.max_rows\", 160)\n",
    "pd.set_option(\"display.max_columns\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebccbff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify \n",
    "# %notify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b32ae8",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8f1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for model training\n",
    "data = pd.read_csv('../project_3/datasets/data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580e348",
   "metadata": {},
   "source": [
    "## Data Dictionary:\n",
    "\n",
    "**Dataset name: data_2**\n",
    "- Size: 9982 observations, 2 variables\n",
    "- Description: Final dataset that contains scrapped data from Reddit\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|:---|:---|:---|:---|\n",
    "|**subreddit**|*integer*|data|Subreddit categories. 0 refers to csMajors, 1 refers to codingbootcamp| \n",
    "|**text**|*string*|data|Posts extracted from csMajor and codingbootcamp subreddit|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846fa980",
   "metadata": {},
   "source": [
    "## Setting Up Data For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda6eb9",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98a25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"subreddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba81392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efa1f0",
   "metadata": {},
   "source": [
    "## Vectorizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbadaf",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452816c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK(Natural Language Toolkit).\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# add more stopwords\n",
    "add_stopword = stopword + [\"want\",\"one\",\"anyone\",\"like\",\"im\",\"get\",\"would\",\"got\"] + ['really','also','ive','know','dont','go','much','lot','take','think','even','getting','back',\"\"]\n",
    "\n",
    "# Lemmatizing\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6606c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove punctuation, tokenize, remove stopwords and lemmatize\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    # \\W matches any non-word character (equivalent to [^a-zA-Z0-9_]). This does not include spaces i.e. \\s\n",
    "    # Add a + just in case there are 2 or more spaces between certain words\n",
    "    tokens = re.split('\\W+', text)\n",
    "    \n",
    "    # apply stemming and stopwords exclusion within the same step\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in add_stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03128e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417d7b3",
   "metadata": {},
   "source": [
    "### Setting up pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb6dc3",
   "metadata": {},
   "source": [
    "#### Pipeline Count Vectorizer + Bernoulli Naive Bayers + Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4e1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pipeline with 2 stages:\n",
    "# 1. CountVectorizer (transformer) + clean text\n",
    "# 2. Bernoulli Naive Bayes (estimator)\n",
    "\n",
    "pipe_cv_ber_cln = Pipeline([\n",
    "    (\"cv\", CountVectorizer(analyzer = clean_text)),\n",
    "    ('ber', BernoulliNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75eb89b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cv',\n",
       "   CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>)),\n",
       "  ('ber', BernoulliNB())],\n",
       " 'verbose': False,\n",
       " 'cv': CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>),\n",
       " 'ber': BernoulliNB(),\n",
       " 'cv__analyzer': <function __main__.clean_text(text)>,\n",
       " 'cv__binary': False,\n",
       " 'cv__decode_error': 'strict',\n",
       " 'cv__dtype': numpy.int64,\n",
       " 'cv__encoding': 'utf-8',\n",
       " 'cv__input': 'content',\n",
       " 'cv__lowercase': True,\n",
       " 'cv__max_df': 1.0,\n",
       " 'cv__max_features': None,\n",
       " 'cv__min_df': 1,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__preprocessor': None,\n",
       " 'cv__stop_words': None,\n",
       " 'cv__strip_accents': None,\n",
       " 'cv__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cv__tokenizer': None,\n",
       " 'cv__vocabulary': None,\n",
       " 'ber__alpha': 1.0,\n",
       " 'ber__binarize': 0.0,\n",
       " 'ber__class_prior': None,\n",
       " 'ber__fit_prior': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the params for gridsearch\n",
    "pipe_cv_ber_cln.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fdc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "params_cv_ber = {\n",
    "    'cv__max_features': [3_000],\n",
    "    'cv__min_df': [5],\n",
    "    'cv__max_df': [0.4],\n",
    "    'ber__alpha': [0],\n",
    "    'ber__binarize' : [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65e572c1",
   "metadata": {},
   "source": [
    "#hyperparameter tuning (documented tested range)\n",
    "params_cv_ber = {\n",
    "    'cv__max_features': [2_000,3_000,4_000,4_300,4_500, 5_000,,9_000,16_000],\n",
    "    'cv__min_df': [2,3,4,5,6,8],\n",
    "    'cv__max_df': [0.1,0.3,0.4,0.5,0.7,0.8,.9,.95],\n",
    "    'ber__alpha': [0,0.3,0.5,0.6,1],\n",
    "    'ber__binarize' : [0,0.1,0.2]\n",
    "}\n",
    "\n",
    "{'ber__alpha': 0,\n",
    " 'ber__binarize': 0,\n",
    " 'cv__max_df': 0.4,\n",
    " 'cv__max_features': 3000,\n",
    " 'cv__min_df': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fdf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "gs_cv_ber_cln = GridSearchCV(pipe_cv_ber_cln, # what object are we optimizing?\n",
    "                  param_grid=params_cv_ber, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231cb7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>)),\n",
       "                                       ('ber', BernoulliNB())]),\n",
       "             param_grid={'ber__alpha': [0], 'ber__binarize': [0],\n",
       "                         'cv__max_df': [0.4], 'cv__max_features': [3000],\n",
       "                         'cv__min_df': [5]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_cv_ber_cln.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b52619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ber__alpha': 0,\n",
       " 'ber__binarize': 0,\n",
       " 'cv__max_df': 0.4,\n",
       " 'cv__max_features': 3000,\n",
       " 'cv__min_df': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params: \n",
    "gs_cv_ber_cln.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47b77161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross validation score: 0.8274108519665052\n",
      "score on train set: 0.8461127437884051\n",
      "score on test set: 0.8421474358974359\n"
     ]
    }
   ],
   "source": [
    "# Best score: Mean cross-validated score of the best_estimator (we did a cv = 5)\n",
    "print(f'best cross validation score: {gs_cv_ber_cln.best_score_}')\n",
    "\n",
    "# Score model on training set.\n",
    "print(f'score on train set: {gs_cv_ber_cln.score(X_train, y_train)}')\n",
    "\n",
    "# Score model on testing set.\n",
    "print(f'score on test set: {gs_cv_ber_cln.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7d930",
   "metadata": {},
   "source": [
    "- best cross validation score: 0.8274108519665052\n",
    "- score on train set: 0.8461127437884051\n",
    "- score on test set: 0.8421474358974359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba523fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      1248\n",
      "           1       0.91      0.76      0.83      1248\n",
      "\n",
      "    accuracy                           0.84      2496\n",
      "   macro avg       0.85      0.84      0.84      2496\n",
      "weighted avg       0.85      0.84      0.84      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_ber_cln = gs_cv_ber_cln.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_cv_ber_cln))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6bdbc",
   "metadata": {},
   "source": [
    "#### Pipeline Count Vectorizer + Multinomial Naive Bayers + Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41af1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pipeline with 2 stages:\n",
    "# 1. CountVectorizer (transformer) + clean text\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cv_mnb_cln = Pipeline([\n",
    "    (\"cv\", CountVectorizer(analyzer = clean_text)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed72aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "params_cv_mnb = {\n",
    "    'cv__max_features': [5_000, 7_000, 9_000, 11_000,13_000],\n",
    "    'cv__min_df': [3],\n",
    "    'cv__max_df': [.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "076e956b",
   "metadata": {},
   "source": [
    "#hyperparameter tuning (documented tested range)\n",
    "params_cv_ber = {\n",
    "    'cv__max_features': [2_000, 3_000, 4_000, 5_000, 5_500, 6_000, 6_500, 7_000,],\n",
    "    'cv__min_df': [0, 1, 2,3],\n",
    "    'cv__max_df': [.2,.3,.4,.7,.9,.95]\n",
    "}\n",
    "'cv__max_df': 0.4, 'cv__max_features': 5000, 'cv__min_df': 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc620780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "gs_cv_mnb_cln = GridSearchCV(pipe_cv_mnb_cln, # what object are we optimizing?\n",
    "                  param_grid=params_cv_mnb, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79d4d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>)),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid={'cv__max_df': [0.4],\n",
       "                         'cv__max_features': [5000, 7000, 9000, 11000, 13000],\n",
       "                         'cv__min_df': [3]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_cv_mnb_cln.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ceda4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.4, 'cv__max_features': 5000, 'cv__min_df': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params:\n",
    "gs_cv_mnb_cln.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "496f3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross validation score: 0.9122355971399854\n",
      "score on train set: 0.9321399946566925\n",
      "score on test set: 0.9314903846153846\n"
     ]
    }
   ],
   "source": [
    "# Best score: Mean cross-validated score of the best_estimator (we did a cv = 5)\n",
    "print(f'best cross validation score: {gs_cv_mnb_cln.best_score_}')\n",
    "\n",
    "# Score model on training set.\n",
    "print(f'score on train set: {gs_cv_mnb_cln.score(X_train, y_train)}')\n",
    "\n",
    "# Score model on testing set.\n",
    "print(f'score on test set: {gs_cv_mnb_cln.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a124ce9",
   "metadata": {},
   "source": [
    "- best cross validation score: 0.9122355971399854\n",
    "- score on train set: 0.9321399946566925\n",
    "- score on test set: 0.9314903846153846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea43523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1248\n",
      "           1       0.92      0.95      0.93      1248\n",
      "\n",
      "    accuracy                           0.93      2496\n",
      "   macro avg       0.93      0.93      0.93      2496\n",
      "weighted avg       0.93      0.93      0.93      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_mnb = gs_cv_mnb_cln.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_cv_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0621e2e",
   "metadata": {},
   "source": [
    "#### Pipeline Count Vectorizer + Logisitic Regression + Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dc81a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pipeline with 2 stages:\n",
    "# 1. CountVectorizer (transformer) + clean text\n",
    "# 2. Logistic Regression (estimator)\n",
    "\n",
    "pipe_cv_lg = Pipeline([\n",
    "    (\"cv\", CountVectorizer(analyzer = clean_text)),\n",
    "    ('lg', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8b01eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "params_cv_lg = {\n",
    "    'cv__max_features': [7_000],\n",
    "    'cv__min_df': [0],\n",
    "    'cv__max_df': [0.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bd7d0d6",
   "metadata": {},
   "source": [
    "#hyperparameter tuning (documented range)\n",
    "params_cv_ber = {\n",
    "    'cv__max_features': [2_000, 3_000, 4_000, 5_000, 6_000, 7_000, 9000, 11000, 13000, 15000],\n",
    "    'cv__min_df': [0, 1, 2,3],\n",
    "    'cv__max_df': [0.3,.4,.7,.9,.95]\n",
    "}\n",
    "\n",
    "{'cv__max_df': 0.4, 'cv__max_features': 7000, 'cv__min_df': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a9061ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "gs_cv_lg = GridSearchCV(pipe_cv_lg, # what object are we optimizing?\n",
    "                  param_grid=params_cv_lg, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04e6b53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>)),\n",
       "                                       ('lg',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             param_grid={'cv__max_df': [0.4], 'cv__max_features': [7000],\n",
       "                         'cv__min_df': [0]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_cv_lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6752dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.4, 'cv__max_features': 7000, 'cv__min_df': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params:\n",
    "gs_cv_lg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "085d096b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross validation score: 0.9249257750035005\n",
      "score on train set: 0.986775313919316\n",
      "score on test set: 0.9342948717948718\n"
     ]
    }
   ],
   "source": [
    "# Best score: Mean cross-validated score of the best_estimator (we did a cv = 5)\n",
    "print(f'best cross validation score: {gs_cv_lg.best_score_}') \n",
    "\n",
    "# Score model on training set.\n",
    "print(f'score on train set: {gs_cv_lg.score(X_train, y_train)}')\n",
    "\n",
    "# Score model on testing set.\n",
    "print(f'score on test set: {gs_cv_lg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45d3b9",
   "metadata": {},
   "source": [
    "- best cross validation score: 0.9249257750035005\n",
    "- score on train set: 0.986775313919316\n",
    "- score on test set: 0.9342948717948718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd6a9c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      1248\n",
      "           1       0.93      0.94      0.93      1248\n",
      "\n",
      "    accuracy                           0.93      2496\n",
      "   macro avg       0.93      0.93      0.93      2496\n",
      "weighted avg       0.93      0.93      0.93      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_lg = gs_cv_lg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_cv_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a705a",
   "metadata": {},
   "source": [
    "#### Pipeline Count Vectorizer + KNN + Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9df637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pipeline with 2 stages:\n",
    "# 1. Countvector + clean text\n",
    "# 2. KNN (estimator)\n",
    "\n",
    "pipe_cv_knn = Pipeline([\n",
    "    (\"cv\", CountVectorizer(analyzer = clean_text)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418a8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "params_cv_knn = {\n",
    "    'cv__max_features': [16_000],\n",
    "    'cv__min_df': [0],\n",
    "    'cv__max_df': [0.4],\n",
    "    'knn__n_neighbors': [3]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f19970c3",
   "metadata": {},
   "source": [
    "#hyperparameter tuning (documentation)\n",
    "params_cv_knn = {\n",
    "    'cv__max_features': [7_000,11_000,13_000,16_000],\n",
    "    'cv__min_df': [0,0.5, 1],\n",
    "    'cv__max_df': [0.4,0.6,0.9],\n",
    "    'knn__n_neighbors': [3,5,7,11]\n",
    "}\n",
    "\n",
    "#best features:\n",
    "{'cv__max_df': 0.4,\n",
    " 'cv__max_features': 16000,\n",
    " 'cv__min_df': 0,\n",
    " 'knn__n_neighbors': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08d779e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "gs_cv_knn = GridSearchCV(pipe_cv_knn, # what object are we optimizing?\n",
    "                  param_grid=params_cv_knn, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "346aae34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(analyzer=<function clean_text at 0x000002B0F4228F70>)),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'cv__max_df': [0.4], 'cv__max_features': [16000],\n",
       "                         'cv__min_df': [0], 'knn__n_neighbors': [3]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_cv_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65a2013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.4,\n",
       " 'cv__max_features': 16000,\n",
       " 'cv__min_df': 0,\n",
       " 'knn__n_neighbors': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params:\n",
    "gs_cv_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95c22625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross validation score: 0.8254079141817237\n",
      "score on train set: 0.9048891263692226\n",
      "score on test set: 0.8369391025641025\n"
     ]
    }
   ],
   "source": [
    "# Best score: Mean cross-validated score of the best_estimator (we did a cv = 5)\n",
    "print(f'best cross validation score: {gs_cv_knn.best_score_}') \n",
    "\n",
    "# Score model on training set.\n",
    "print(f'score on train set: {gs_cv_knn.score(X_train, y_train)}')\n",
    "\n",
    "# Score model on testing set.\n",
    "print(f'score on test set: {gs_cv_knn.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea6b56",
   "metadata": {},
   "source": [
    "- best cross validation score: 0.8254079141817237\n",
    "- score on train set: 0.9048891263692226\n",
    "- score on test set: 0.8369391025641025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33d807fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      1248\n",
      "           1       0.78      0.93      0.85      1248\n",
      "\n",
      "    accuracy                           0.84      2496\n",
      "   macro avg       0.85      0.84      0.84      2496\n",
      "weighted avg       0.85      0.84      0.84      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_knn = gs_cv_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_cv_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64232e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"f549ed3a-224d-43af-b8dd-334ab610ba58\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"f549ed3a-224d-43af-b8dd-334ab610ba58\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%notify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d3065",
   "metadata": {},
   "source": [
    "## Summary on Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b8e0b",
   "metadata": {},
   "source": [
    "|**Vectorization Method**|**Model**|**Train Results**|**Test Results**|\n",
    "|:---|:---|:---:|:---:|\n",
    "|Count Vectorizer|Naive Bayes - Bernoulli|0.84611|0.84215|\n",
    "|Count Vectorizer|Naive Bayes - Multinomial|0.93214|0.93149|\n",
    "|Count Vectorizer|Logistic Regression|0.98678|0.93429|\n",
    "|Count Vectorizer|K-Nearest Neighbours|0.90489|0.83694|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
